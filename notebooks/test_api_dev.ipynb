{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException, Request\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Literal, Dict\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hashlib\n",
    "import os\n",
    "import logging\n",
    "from functools import lru_cache\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "os.chdir(\"/Users/ajohnca/Documents/Applied Data Science/Summer 2025/Python for ML Engineering/assignments/score_headlines\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define models (stub local models for notebook testing)\n",
    "@lru_cache()\n",
    "def get_embedding_model() -> SentenceTransformer:\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")  # Load from HF directly in notebook\n",
    "\n",
    "@lru_cache()\n",
    "def get_svm_model():\n",
    "    # Load a dummy or pretrained model\n",
    "    return joblib.load(\"models/svm.joblib\")  # Update path if needed\n",
    "\n",
    "embedding_model = get_embedding_model()\n",
    "svm_model = get_svm_model()\n",
    "\n",
    "# Helper function\n",
    "def generate_headline_id(text: str) -> str:\n",
    "    normalized = text.lower().strip()\n",
    "    return hashlib.blake2b(normalized.encode(\"utf-8\"), digest_size=10).hexdigest()\n",
    "\n",
    "# Define FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/status\")\n",
    "def status():\n",
    "    return {\"status\": \"OK\"}\n",
    "\n",
    "class HeadlineRequest(BaseModel):\n",
    "    headlines: List[str]\n",
    "    return_ids: bool = False\n",
    "\n",
    "@app.post(\"/score_headlines\")\n",
    "def score_headlines(request: Request, payload: HeadlineRequest) -> Dict[str, List]:\n",
    "    headlines = payload.headlines\n",
    "    return_ids = payload.return_ids\n",
    "\n",
    "    logger.info(f\"Received request from {request.client.host} with {len(headlines)} headline(s).\")\n",
    "\n",
    "    if not headlines:\n",
    "        raise HTTPException(status_code=400, detail=\"No headlines provided.\")\n",
    "\n",
    "    try:\n",
    "        embeddings = embedding_model.encode(headlines)\n",
    "        preds = svm_model.predict(embeddings)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Prediction error\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "    if return_ids:\n",
    "        results = [{\"id\": generate_headline_id(text), \"label\": label} for text, label in zip(headlines, preds)]\n",
    "        return {\"results\": results}\n",
    "    else:\n",
    "        return {\"labels\": preds.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://testserver/status \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Received request from testclient with 2 headline(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200 {'status': 'OK'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3faa9734ee94874b2c4d96a6eaed297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://testserver/score_headlines \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Headlines: 200 {'results': [{'id': 'eac3c48b39894338157b', 'label': 'Neutral'}, {'id': '182d3ee7fdae04e43bd2', 'label': 'Neutral'}]}\n"
     ]
    }
   ],
   "source": [
    "from fastapi.testclient import TestClient\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "# Test status\n",
    "response = client.get(\"/status\")\n",
    "print(\"Status:\", response.status_code, response.json())\n",
    "\n",
    "# Test scoring endpoint\n",
    "payload = {\n",
    "    \"headlines\": [\"Stocks rally after inflation slows\", \"War tensions increase in Middle East\"],\n",
    "    \"return_ids\": True\n",
    "}\n",
    "response = client.post(\"/score_headlines\", json=payload)\n",
    "print(\"Score Headlines:\", response.status_code, response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5e1bceba084e1186350b92083fdd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = embedding_model.encode(payload[\"headlines\"])\n",
    "logger.debug(f\"Embeddings shape: {embeddings.shape}\")\n",
    "logger.debug(f\"Sample embedding (first headline): {embeddings[0][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101,  6089,  2024, 12894,   102]])\n",
      "Tokens: ['[CLS]', 'markets', 'are', 'crashing', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = embedding_model.tokenizer\n",
    "tokens = tokenizer(\"Markets are crashing\", return_tensors=\"pt\")\n",
    "\n",
    "print(\"Input IDs:\", tokens[\"input_ids\"])\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e277d484535c49488dc289535d9c310b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Test predictions: [('7 Sublime Cookies for a Joyous Holiday Season. Lemony turmeric, gingery cheesecake, boozy almond: This year’s Cookie Week has something for everyone.', 'Optimistic'), ('Markets are soaring', 'Neutral')]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = get_embedding_model()\n",
    "svm_model = get_svm_model()\n",
    "\n",
    "test_headlines = [\n",
    "    \"7 Sublime Cookies for a Joyous Holiday Season. Lemony turmeric, gingery cheesecake, boozy almond: This year’s Cookie Week has something for everyone.\",\n",
    "    \"Markets are soaring\"\n",
    "]\n",
    "\n",
    "embeddings = embedding_model.encode(test_headlines)\n",
    "preds = svm_model.predict(embeddings)\n",
    "\n",
    "logger.info(f\"Test predictions: {list(zip(test_headlines, preds))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
